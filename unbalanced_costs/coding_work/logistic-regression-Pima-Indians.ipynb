{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controversial-barrier",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "devoted-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cross-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('./Data/pima-indians-diabetes-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-madness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>Triceps_skinfold_thickness</th>\n",
       "      <th>2_Hour_serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>diabetes_pedigree_function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class_Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_concentration  blood_pressure  \\\n",
       "0                 1                     85              66   \n",
       "1                 8                    183              64   \n",
       "2                 1                     89              66   \n",
       "3                 0                    137              40   \n",
       "4                 5                    116              74   \n",
       "..              ...                    ...             ...   \n",
       "763               2                    122              70   \n",
       "764               5                    121              72   \n",
       "765               1                    126              60   \n",
       "766               1                     93              70   \n",
       "767               6                    148              72   \n",
       "\n",
       "     Triceps_skinfold_thickness  2_Hour_serum_insulin   BMI  \\\n",
       "0                            29                     0  26.6   \n",
       "1                             0                     0  23.3   \n",
       "2                            23                    94  28.1   \n",
       "3                            35                   168  43.1   \n",
       "4                             0                     0  25.6   \n",
       "..                          ...                   ...   ...   \n",
       "763                          27                     0  36.8   \n",
       "764                          23                   112  26.2   \n",
       "765                           0                     0  30.1   \n",
       "766                          31                     0  30.4   \n",
       "767                          35                     0  33.6   \n",
       "\n",
       "     diabetes_pedigree_function  Age  Class_Variable  \n",
       "0                         0.351   31               0  \n",
       "1                         0.672   32               1  \n",
       "2                         0.167   21               0  \n",
       "3                         2.288   33               1  \n",
       "4                         0.201   30               0  \n",
       "..                          ...  ...             ...  \n",
       "763                       0.340   27               0  \n",
       "764                       0.245   30               0  \n",
       "765                       0.349   47               1  \n",
       "766                       0.315   23               0  \n",
       "767                       0.627   50               1  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "artificial-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['times_pregnant', 'glucose_concentration', 'blood_pressure', 'Triceps_skinfold_thickness',\n",
    "              '2_Hour_serum_insulin', 'BMI', 'diabetes_pedigree_function', 'Age']\n",
    "outcome_col = 'Class_Variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes[feature_cols].to_numpy()\n",
    "y = diabetes[outcome_col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blocked-account",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>Triceps_skinfold_thickness</th>\n",
       "      <th>2_Hour_serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>diabetes_pedigree_function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class_Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_concentration  blood_pressure  \\\n",
       "1                 8                    183              64   \n",
       "3                 0                    137              40   \n",
       "5                 3                     78              50   \n",
       "7                 2                    197              70   \n",
       "8                 8                    125              96   \n",
       "..              ...                    ...             ...   \n",
       "756               0                    123              72   \n",
       "758               6                    190              92   \n",
       "760               9                    170              74   \n",
       "765               1                    126              60   \n",
       "767               6                    148              72   \n",
       "\n",
       "     Triceps_skinfold_thickness  2_Hour_serum_insulin   BMI  \\\n",
       "1                             0                     0  23.3   \n",
       "3                            35                   168  43.1   \n",
       "5                            32                    88  31.0   \n",
       "7                            45                   543  30.5   \n",
       "8                             0                     0   0.0   \n",
       "..                          ...                   ...   ...   \n",
       "756                           0                     0  36.3   \n",
       "758                           0                     0  35.5   \n",
       "760                          31                     0  44.0   \n",
       "765                           0                     0  30.1   \n",
       "767                          35                     0  33.6   \n",
       "\n",
       "     diabetes_pedigree_function  Age  Class_Variable  \n",
       "1                         0.672   32               1  \n",
       "3                         2.288   33               1  \n",
       "5                         0.248   26               1  \n",
       "7                         0.158   53               1  \n",
       "8                         0.232   54               1  \n",
       "..                          ...  ...             ...  \n",
       "756                       0.258   52               1  \n",
       "758                       0.278   66               1  \n",
       "760                       0.403   43               1  \n",
       "765                       0.349   47               1  \n",
       "767                       0.627   50               1  \n",
       "\n",
       "[268 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes[diabetes[\"Class_Variable\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "floating-label",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f3887c4f064a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "following-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "little-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the training data\n",
    "means = X_train.mean(axis=0)\n",
    "stds = X_train.std(axis=0)\n",
    "X_train = zscore(X_train, axis=0, ddof=0, nan_policy='propagate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the test data according to the training data\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[i])):\n",
    "        X_test[i][j] = (X_test[i][j] - means[j]) / stds[j] \n",
    "                         \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-harvest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adapted-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model with class weights\n",
    "lr_weights = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_weights.fit(X_train, y_train)\n",
    "lr_pred_weights = lr_weights.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cutting-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model without class weights\n",
    "lr_no_weights = LogisticRegression()\n",
    "lr_no_weights.fit(X_train, y_train)\n",
    "lr_pred_no_weights = lr_no_weights.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smart-hawaii",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74, 16, 23, 41])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for weights\n",
    "metrics.confusion_matrix(lr_pred_weights, y_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opened-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83, 22, 14, 35])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for no weights\n",
    "metrics.confusion_matrix(lr_pred_no_weights, y_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blessed-campus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467532467532467"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suburban-artwork",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_no_weights.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-jenny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-testament",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-journalism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-library",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "binding-pocket",
   "metadata": {},
   "source": [
    "# Logistic Regression with Our Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "southeast-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionBinaryMod(LogisticRegression):\n",
    "    def __init__(self, loss_11, loss_10, loss_01, loss_00, **kwds):\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "        # comes from equation 8 in the writeup\n",
    "        self.loss_11 = loss_11\n",
    "        self.loss_10 = loss_10\n",
    "        self.loss_01 = loss_01\n",
    "        self.loss_00 = loss_00\n",
    "        self.threshold = (loss_01 - loss_00) / ((loss_01 - loss_00) + (loss_10 - loss_11))\n",
    "        print(f\"self.threshold: {self.threshold}\")\n",
    "    \n",
    "    # override the predict function to predict according to our threshold\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        predictions = [1 if probs[i][1] >= self.threshold else 0 for i in range(len(probs))]\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    # write a score function that will calculate the score of classifications given our costs\n",
    "    def score_with_costs(self, X, y, sample_weight=None):\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        give_loss_vectorized = np.vectorize(self.give_loss)\n",
    "        losses = give_loss_vectorized(y, y_pred)\n",
    "        \n",
    "        return np.average(losses, weights=sample_weight)\n",
    "        \n",
    "        \n",
    "    def give_loss(self, y, y_pred):\n",
    "        if y == 1 and y_pred == 1:\n",
    "            return self.loss_11\n",
    "        elif y == 1 and y_pred == 0:\n",
    "            return self.loss_10\n",
    "        elif y == 0 and y_pred == 1:\n",
    "            return self.loss_01\n",
    "        elif y == 0 and y_pred == 0:\n",
    "            return self.loss_00\n",
    "        else:\n",
    "            raise Exception(f\"Expected y: {y} and y_pred: {y_pred} to equal to 0 or 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-bangkok",
   "metadata": {},
   "source": [
    "# Logistic Regression- with additional cost sensitive score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "advised-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionJustScore(LogisticRegression):\n",
    "    def __init__(self, loss_11, loss_10, loss_01, loss_00, **kwds):\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "        # comes from equation 8 in the writeup\n",
    "        self.loss_11 = loss_11\n",
    "        self.loss_10 = loss_10\n",
    "        self.loss_01 = loss_01\n",
    "        self.loss_00 = loss_00\n",
    "\n",
    "        \n",
    "    # write a score function that will calculate the score of classifications given our costs\n",
    "    def score_with_costs(self, X, y, sample_weight=None):\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        give_loss_vectorized = np.vectorize(self.give_loss)\n",
    "        losses = give_loss_vectorized(y, y_pred)\n",
    "        \n",
    "        return np.average(losses, weights=sample_weight)\n",
    "        \n",
    "        \n",
    "    def give_loss(self, y, y_pred):\n",
    "        if y == 1 and y_pred == 1:\n",
    "            return self.loss_11\n",
    "        elif y == 1 and y_pred == 0:\n",
    "            return self.loss_10\n",
    "        elif y == 0 and y_pred == 1:\n",
    "            return self.loss_01\n",
    "        elif y == 0 and y_pred == 0:\n",
    "            return self.loss_00\n",
    "        else:\n",
    "            raise Exception(f\"Expected y: {y} and y_pred: {y_pred} to equal to 0 or 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-modern",
   "metadata": {},
   "source": [
    "# Dummy Classifier- with additional cost sensitive score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "drawn-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyClassifierJustScore(DummyClassifier):\n",
    "    def __init__(self, loss_11, loss_10, loss_01, loss_00, **kwds):\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "        # comes from equation 8 in the writeup\n",
    "        self.loss_11 = loss_11\n",
    "        self.loss_10 = loss_10\n",
    "        self.loss_01 = loss_01\n",
    "        self.loss_00 = loss_00\n",
    "\n",
    "        \n",
    "    # write a score function that will calculate the score of classifications given our costs\n",
    "    def score_with_costs(self, X, y, sample_weight=None):\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        give_loss_vectorized = np.vectorize(self.give_loss)\n",
    "        losses = give_loss_vectorized(y, y_pred)\n",
    "        \n",
    "        return np.average(losses, weights=sample_weight)\n",
    "        \n",
    "        \n",
    "    def give_loss(self, y, y_pred):\n",
    "        if y == 1 and y_pred == 1:\n",
    "            return self.loss_11\n",
    "        elif y == 1 and y_pred == 0:\n",
    "            return self.loss_10\n",
    "        elif y == 0 and y_pred == 1:\n",
    "            return self.loss_01\n",
    "        elif y == 0 and y_pred == 0:\n",
    "            return self.loss_00\n",
    "        else:\n",
    "            raise Exception(f\"Expected y: {y} and y_pred: {y_pred} to equal to 0 or 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-posting",
   "metadata": {},
   "source": [
    "### Penalties for the following classifiers defined once here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "southeast-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_11 = 100000 # loss associated with correctly assigning class 1\n",
    "loss_10 = 7500000 # loss associated with assigning class 0 when we should assign class 1\n",
    "loss_01 = 100000 # loss associated with assigning class 1 when we should assign class 0\n",
    "loss_00 = 0 # loss associated with correctly assigning class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-poster",
   "metadata": {},
   "source": [
    "### Logistic Regression with our prediction threshold- no reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "breathing-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.threshold: 0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "lr_cost_sensitive = LogisticRegressionBinaryMod(loss_11, loss_10, loss_01, loss_00)\n",
    "lr_cost_sensitive.fit(X_train, y_train)\n",
    "lr_cost_sensitive_pred = lr_cost_sensitive.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adaptive-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [ 2 95  0 57]\n",
      "precision: 0.375\n",
      "recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, lr_cost_sensitive_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caroline-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98701.2987012987"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cost_sensitive.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "obvious-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38311688311688313"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cost_sensitive.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-innocent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "individual-america",
   "metadata": {},
   "source": [
    "### Logistic Regression with our prediction threshold- reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adolescent-prayer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.threshold: 0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "lr_cost_sensitive_reweight = LogisticRegressionBinaryMod(loss_11, loss_10, loss_01, loss_00, class_weight=\"balanced\")\n",
    "lr_cost_sensitive_reweight.fit(X_train, y_train)\n",
    "lr_cost_sensitive_reweight_pred = lr_cost_sensitive_reweight.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "designing-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  0, 95, 57])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "metrics.confusion_matrix(y_test, lr_cost_sensitive_reweight_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fabulous-forth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98701.2987012987"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cost_sensitive_reweight.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "polish-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38311688311688313"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cost_sensitive_reweight.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-backing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-attention",
   "metadata": {},
   "source": [
    "### Logistic Regression with standard prediction threshold of 0.5- no reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exclusive-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionJustScore(loss_11, loss_10, loss_01, loss_00)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "consecutive-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [83 14 22 35]\n",
      "precision: 0.7142857142857143\n",
      "recall: 0.6140350877192983\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, lr_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "atomic-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103246.7532467532"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "signed-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-eagle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mature-phoenix",
   "metadata": {},
   "source": [
    "### Logistic Regression with standard prediction threshold of 0.5- reweighting (according to Elkan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "serial-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0: 0.013 / (1-0.013), 1: 1}\n",
    "weights2 = {0: 0.25, 1: 1}\n",
    "lr_reweight = LogisticRegressionJustScore(loss_11, loss_10, loss_01, loss_00, class_weight=weights2)\n",
    "lr_reweight.fit(X_train, y_train)\n",
    "lr_reweight_pred = lr_reweight.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nearby-electricity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [62 35  6 51]\n",
      "precision: 0.5930232558139535\n",
      "recall: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, lr_reweight_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "speaking-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533116.8831168832"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_reweight.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "several-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7337662337662337"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_reweight.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-analyst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "third-measure",
   "metadata": {},
   "source": [
    "### Dummy Classifier that ignores features to serve as baseline- always predicts majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "industrial-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier_majority = DummyClassifierJustScore(loss_11, loss_10, loss_01, loss_00)\n",
    "dummy_classifier_majority.fit(X_train, y_train)\n",
    "dummy_classifier_majority_pred = dummy_classifier_majority.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "suspended-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [97  0 57  0]\n",
      "precision: nan\n",
      "recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VillasBoas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, dummy_classifier_majority_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "wicked-vessel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2775974.025974026"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_majority.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eight-irrigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6298701298701299"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_majority.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-topic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "italic-north",
   "metadata": {},
   "source": [
    "### Dummy Classifier that ignores features to serve as baseline- always predict minority class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bigger-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier_minority = DummyClassifierJustScore(loss_11, loss_10, loss_01, loss_00, strategy=\"constant\", constant=1)\n",
    "dummy_classifier_minority.fit(X_train, y_train)\n",
    "dummy_classifier_minority_pred = dummy_classifier_minority.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "conservative-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [ 0 97  0 57]\n",
      "precision: 0.37012987012987014\n",
      "recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, dummy_classifier_minority_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "linear-uruguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_minority.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "empty-archive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37012987012987014"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_minority.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-teddy",
   "metadata": {},
   "source": [
    "### Dummy Classifier that ignores features to serve as baseline- pick randomly according to prior classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "alternate-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier_stratified = DummyClassifierJustScore(loss_11, loss_10, loss_01, loss_00, strategy=\"stratified\", random_state=42)\n",
    "dummy_classifier_stratified.fit(X_train, y_train)\n",
    "dummy_classifier_stratified_pred = dummy_classifier_stratified.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "tutorial-beverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [67 30 39 18]\n",
      "precision: 0.375\n",
      "recall: 0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, dummy_classifier_stratified_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "developing-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1930519.4805194805"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_stratified.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "searching-palestinian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.551948051948052"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_stratified.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-wrong",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-alexandria",
   "metadata": {},
   "source": [
    "### Dummy Classifier that ignores features to serve as baseline- pick totally randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "better-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier_random = DummyClassifierJustScore(loss_11, loss_10, loss_01, loss_00, strategy=\"uniform\", random_state=42)\n",
    "dummy_classifier_random.fit(X_train, y_train)\n",
    "dummy_classifier_random_pred = dummy_classifier_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "quality-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [42 55 30 27]\n",
      "precision: 0.32926829268292684\n",
      "recall: 0.47368421052631576\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, dummy_classifier_random_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "clean-bones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514285.7142857143"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_random.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "polish-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44805194805194803"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier_random.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-slave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-natural",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
