{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquired-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "official-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('./Data/pima-indians-diabetes-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "packed-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['times_pregnant', 'glucose_concentration', 'blood_pressure', 'Triceps_skinfold_thickness',\n",
    "              '2_Hour_serum_insulin', 'BMI', 'diabetes_pedigree_function', 'Age']\n",
    "outcome_col = 'Class_Variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "banner-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes[feature_cols].to_numpy()\n",
    "y = diabetes[outcome_col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contemporary-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suitable-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the training data\n",
    "means = X_train.mean(axis=0)\n",
    "stds = X_train.std(axis=0)\n",
    "X_train = zscore(X_train, axis=0, ddof=0, nan_policy='propagate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confirmed-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the test data according to the training data\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[i])):\n",
    "        X_test[i][j] = (X_test[i][j] - means[j]) / stds[j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trained-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Cost Values\n",
    "loss_11 = 100000 # loss associated with correctly assigning class 1\n",
    "loss_10 = 7500000 # loss associated with assigning class 0 when we should assign class 1\n",
    "loss_01 = 100000 # loss associated with assigning class 1 when we should assign class 0\n",
    "loss_00 = 0 # loss associated with correctly assigning class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-hundred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "representative-vulnerability",
   "metadata": {},
   "source": [
    "### Random Forest with our prediction threshold- no reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "internal-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestBinaryMod(RandomForestClassifier):\n",
    "    def __init__(self, loss_11, loss_10, loss_01, loss_00, **kwds):\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "        # comes from equation 8 in the writeup\n",
    "        self.loss_11 = loss_11\n",
    "        self.loss_10 = loss_10\n",
    "        self.loss_01 = loss_01\n",
    "        self.loss_00 = loss_00\n",
    "        self.threshold = (loss_01 - loss_00) / ((loss_01 - loss_00) + (loss_10 - loss_11))\n",
    "        print(f\"self.threshold: {self.threshold}\")\n",
    "    \n",
    "    # override the predict function to predict according to our threshold\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        predictions = [1 if probs[i][1] >= self.threshold else 0 for i in range(len(probs))]\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    # write a score function that will calculate the score of classifications given our costs\n",
    "    def score_with_costs(self, X, y, sample_weight=None):\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        give_loss_vectorized = np.vectorize(self.give_loss)\n",
    "        losses = give_loss_vectorized(y, y_pred)\n",
    "        \n",
    "        return np.average(losses, weights=sample_weight)\n",
    "        \n",
    "        \n",
    "    def give_loss(self, y, y_pred):\n",
    "        if y == 1 and y_pred == 1:\n",
    "            return self.loss_11\n",
    "        elif y == 1 and y_pred == 0:\n",
    "            return self.loss_10\n",
    "        elif y == 0 and y_pred == 1:\n",
    "            return self.loss_01\n",
    "        elif y == 0 and y_pred == 0:\n",
    "            return self.loss_00\n",
    "        else:\n",
    "            raise Exception(f\"Expected y: {y} and y_pred: {y_pred} to equal to 0 or 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "finite-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.threshold: 0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "rf_cost_sensitive = RandomForestBinaryMod(loss_11, loss_10, loss_01, loss_00, random_state=42)\n",
    "rf_cost_sensitive.fit(X_train, y_train)\n",
    "rf_cost_sensitive_pred = rf_cost_sensitive.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "amended-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [ 9 88  1 56]\n",
      "precision: 0.3888888888888889\n",
      "recall: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, rf_cost_sensitive_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "impressed-duplicate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142207.7922077922"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cost_sensitive.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "subtle-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42207792207792205"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cost_sensitive.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clinical-strength",
   "metadata": {},
   "source": [
    "### Random Forest with standard prediction threshold of 0.5- no reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sensitive-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestJustScore(RandomForestClassifier):\n",
    "    def __init__(self, loss_11, loss_10, loss_01, loss_00, **kwds):\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "        # comes from equation 8 in the writeup\n",
    "        self.loss_11 = loss_11\n",
    "        self.loss_10 = loss_10\n",
    "        self.loss_01 = loss_01\n",
    "        self.loss_00 = loss_00\n",
    "\n",
    "        \n",
    "    # write a score function that will calculate the score of classifications given our costs\n",
    "    def score_with_costs(self, X, y, sample_weight=None):\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        give_loss_vectorized = np.vectorize(self.give_loss)\n",
    "        losses = give_loss_vectorized(y, y_pred)\n",
    "        \n",
    "        return np.average(losses, weights=sample_weight)\n",
    "        \n",
    "        \n",
    "    def give_loss(self, y, y_pred):\n",
    "        if y == 1 and y_pred == 1:\n",
    "            return self.loss_11\n",
    "        elif y == 1 and y_pred == 0:\n",
    "            return self.loss_10\n",
    "        elif y == 0 and y_pred == 1:\n",
    "            return self.loss_01\n",
    "        elif y == 0 and y_pred == 0:\n",
    "            return self.loss_00\n",
    "        else:\n",
    "            raise Exception(f\"Expected y: {y} and y_pred: {y_pred} to equal to 0 or 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mobile-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_noncost_sensitive = RandomForestJustScore(loss_11, loss_10, loss_01, loss_00, random_state=42)\n",
    "rf_noncost_sensitive.fit(X_train, y_train)\n",
    "rf_noncost_sensitive_pred = rf_noncost_sensitive.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "independent-being",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [81 16 23 34]\n",
      "precision: 0.68\n",
      "recall: 0.5964912280701754\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, rf_noncost_sensitive_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "golden-album",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152597.4025974027"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_noncost_sensitive.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "oriented-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467532467532467"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_noncost_sensitive.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-colon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "formed-chaos",
   "metadata": {},
   "source": [
    "### Random Forest with standard prediction threshold of 0.5- reweighting according to Elkan\n",
    "##### [To ignore, Elkan claims it's difficult to do reweighting for tree based methods, need to look into this with more time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dominican-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0: 0.01, 1: 1}\n",
    "rf_noncost_sensitive_reweight = RandomForestJustScore(loss_11, loss_10, loss_01, loss_00, random_state=42, class_weight=weights)\n",
    "rf_noncost_sensitive_reweight.fit(X_train, y_train)\n",
    "rf_noncost_sensitive_reweight_pred = rf_noncost_sensitive_reweight.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "swiss-lottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [81 16 26 31]\n",
      "precision: 0.6595744680851063\n",
      "recall: 0.543859649122807\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (TN, FP, FN, TP) for cost-sensitive\n",
    "cm = metrics.confusion_matrix(y_test, rf_noncost_sensitive_reweight_pred).ravel()\n",
    "print(f\"confusion matrix: {cm}\")\n",
    "print(f\"precision: {cm[3] / (cm[3] + cm[1])}\")\n",
    "print(f\"recall: {cm[3] / (cm[3] + cm[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "intimate-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296753.2467532468"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_noncost_sensitive_reweight.score_with_costs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "moving-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_noncost_sensitive_reweight.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-panel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-eight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-athens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-mechanism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-better",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
